# Introduction
[Discussion Link](https://github.com/orgs/sit-dia/discussions/1)

## History XR (Historical evolution of immersive technologies)
- 1957: Sensorama
  - 3D images, smells and sounds
- 1968: Sword of Damocles
  - The first HMD
  - Some considers this as the pioneer of VR
- 1987: EyePhone + Data Glove
  - "Virtual Reality" coined by Jaron Lanier, VPL Research
- 1991: Virtuality 1000
  - Stereoscopic 3D
  - Multiplayer
- 1993: SEGA VR
  - 1st Goggles-styled
  - Head tracking
  - Stereo sound
  - LCD screen
- 1994: SEGA VR-1
  - Arcade in Segaworld
  - 3D polygon graphics
- 1995: NINTENDO Virtual Boy
  - 1st portable stereoscopic 3D game console
- 2005: EMagin Z800 3D Visor
  - 0LED
  - Hi-fi sound
  - Head tracking
  - 360 FOV
- 2012: Oculus Rift DK1
  - Created by Palmer Luckey
  - Lightweight
  - Good stereo 3D
  - Price: $300
- 2014: Google CardBoard
  - Cheap
  - Use existing smartphones
- 2015: Samsung Gear VR
- 2016: HTC Vive
- 2016: Ocuclus Rift
- 2016: Playstation VR


## AR, VR, MR and XR
### What are they?
AR (Augment Reality): To augment the perspective of the physical world by overlaying the view of the physical reality
- Examples: Pokemon GO, Ingress, Pikmin Bloom, FNAF: Special Delivery

![image](https://github.com/TobyIO0085/VRNotes/assets/76524945/7c16f947-fddb-40ff-a16d-5a3ed2842257)

VR (Virtual Reality): To encompass the entire vision to a different plane or space
- Examples: Beat Saber, Half-Life: Alyx, Superhot VR, After the Fall

![image](https://github.com/TobyIO0085/VRNotes/assets/76524945/2daa3ff2-7bb2-4ccd-b0fe-7424817378df)

MR (Mixed Reality): Coined/Redefined by Microsoft, a way for the augmented reality to interact with the physical reality
- Examples: Meta Quest 3: Mixed Reality, HoloLens Minecraft

![image](https://github.com/TobyIO0085/VRNotes/assets/76524945/08e2786d-3a05-4649-9cb2-a8c6396549ce)

XR (Extended Reality): Term for encapsulating all of AR, VR and MR

### Immersive Media
Focus on the experience than the technology, coined by IMDA


## Milgram-Kishino's RV Continuum (Reality Virtuality)
![image](https://github.com/TobyIO0085/VRNotes/assets/76524945/465d8bf2-3619-4806-9cd1-dc5faf4f12e8)

[Paper on Milgram-Kishino's RV Continuum](https://doi.org/10.1117/12.197321)

### Dimensions of RV Continuum
![image](https://github.com/TobyIO0085/VRNotes/assets/76524945/17d511e2-a025-452b-a7d9-f7b9dbc3ea27)

The dimensions are split into three categories
- **Extent of World Knowledge** (EWK)
  - `Real World Unmodelled` ~~~~~~~> `Real World Completely Modelled`
  - How much the system is aware of the physical surrounding  ~~~~>
  - Example of actions close to which extent
    - `Real World Unmodelled`: An image of a cat
    - `Real World Completely Modelled`: Aware of user location/user is currently looking at the screen (HoloLens)
- **Reproduction Fidelity** (RF)
  - `No virtual content` ~~~~~~~> `Real and virtual content indistinguishable`
  - How realistic the assets are  ~~~~>
  - Example of actions close to which extent
    - `No virtual content`: A non-shaded 3D cube
    - `Real and virtual content indistinguishable`: Realistic tree with shadows/ Realistic dog with realistic movements
- **Extent of Presence Metaphor** (EPM)
  - `No display` ~~~~~~~> `Indistinguishable from direct viewing`
  - How much realism does the interaction affords ~~~~>
  - Example of actions close to which extent
    - `No display`: User uses mouse and keyboard to type out desires/interactions
    - `Indistinguishable from direct viewing`: User can pick up objects using hands / interact with gestures

### Revisting the RV Continuum
![image](https://github.com/TobyIO0085/VRNotes/assets/76524945/7cc7fa13-8409-4d80-b2f2-9dfc5c4d7eb5)

[Article that revisits paper on Milgram-Kishino's RV Continuum](https://doi.org/10.3389/frvir.2021.647997)

Combines RF and EPM into Immersion Continuum (IM)
- How realistic assets and interaction are ~~~~>

Added Coherenc (CO) to represent user
- How immersed the user is when using the system ~~~~>


# Menti Quiz
## Q1) What is the price of the original Oculuc DK1?
- 300
- 500
- 1100
- 1500
- 2000

<details>
  <summary>Answer</summary>  
  [300]

  History-based.
</details>

## Q2) What experience is this?
![image](https://github.com/TobyIO0085/VRNotes/assets/76524945/1e44de9a-24c6-41fa-b60e-282c30073450)

- AR
- VR
- MR

<details>
  <summary>Answer</summary>  
  [AR]

  Self Explanatory.
</details>

## Q3) What experience is this?
![image](https://github.com/TobyIO0085/VRNotes/assets/76524945/f0e5444d-f633-4d52-9f19-317543837ed3)

- AR
- VR
- MR

<details>
  <summary>Answer</summary>  
  [MR]

  Self Explanatory.
</details>

## Q4) Where should Pokemon GO be placed in the RV Continuum?
![image](https://github.com/TobyIO0085/VRNotes/assets/76524945/7c16f947-fddb-40ff-a16d-5a3ed2842257)
![image](https://github.com/TobyIO0085/VRNotes/assets/76524945/6ad8856e-12c6-4763-bfaf-687e4854a272)

<details>
  <summary>Answer</summary>  
  [B]

  Basing off the real-world environment, closer to Real World.
</details>

## Q5) Where should Beat Saber be placed in the RV Continuum?
![image](https://github.com/TobyIO0085/VRNotes/assets/76524945/2daa3ff2-7bb2-4ccd-b0fe-7424817378df)
![image](https://github.com/TobyIO0085/VRNotes/assets/76524945/6ad8856e-12c6-4763-bfaf-687e4854a272)

<details>
  <summary>Answer</summary>  
  [D] or [E]

  No real-world environment, can be arguable it is not entirely virtual.
  Theory-wise, cannot be entirely virtual since it tracks your hands and user can slightly see real world through gaps in goggles.
</details>

## Q6) Where should Strava be placed in the RV Continuum?
![image](https://github.com/TobyIO0085/VRNotes/assets/76524945/3206420f-3e84-414a-9048-b58602b154d9)
![image](https://github.com/TobyIO0085/VRNotes/assets/76524945/6ad8856e-12c6-4763-bfaf-687e4854a272)

<details>
  <summary>Answer</summary>  
  [B]

  Closer to reality since it tracks user location.
  Not entirely real since ...[Question is below].
</details>

## Q7) Why is Strava not considered to be near the "Real Environment" end of the RV spectrum?
- It has some "Extent of World Knowledge"
- It has some "Reproduction Fidelity"
- It has some "Extent of Presence Metaphor"

<details>
  <summary>Answer</summary>  
  [It has some "Extent of World Knowledge"]

  It is trying to gather data from the real world.
  And the higher the "Extent of World Knowledge", the more virtual it is.
</details>

## Q8) What is the common public perception of the difference between AR and MR?
- They are the same
- AR refers to blending virtual objects onto the real-world
- Virtual entities in MR can interact with real-world objects

<details>
  <summary>Answer</summary>  
  [Virtual entities in MR can interact with real-world objects]

  Coined by Microsoft, that MR can interact with real-world objects.
  Showcases HoloLens as MR hardware.
  ![image](https://github.com/TobyIO0085/VRNotes/assets/76524945/5cf7b722-3f4c-41fc-8972-9387153566ee)

</details>

## Q9) VR was invented in the 21st Century (2001-2100)
- True
- False

<details>
  <summary>Answer</summary>  
  [False]

  Started around 1957 Sensorama and 1968 Sword of Damocles.

</details>

# Evaluating Immersive Experiences
[Discussion Link](https://github.com/orgs/sit-dia/discussions/5)

## 1. Evaluation-first approach
Products are primarily built for the users, not to satisfy the developers. Thus, the quality of the product needs to be evaluated at an early stage in the development lifecycle.

Test Driven Development (TDD): Write test cases FIRST, then write code, refactor code, repeat until all test cases are satisfied.

### What is immersion?
Immersion: "a deep mental involvement in an activity"
Split into two categories: immersion as system properties & immersion in user experiences
Measuring Immersion: depends on the category 

## 2. Immersion as system properties
Immersion (as system properties): "the specifications of the system that produces immersive experiences"
Can be 'measured' by looking at the specs sheet/technical qualities of XR devices
Can also be 'measured' by the software itself - e.g. graphical fidelity, how realistic the AI is, interaction controls(like finger tracking)

## 3. Immersion as user experiences
Immersion (as user experiences): "mixture of psychological and physiological constructs"
Can be measured using experiential constructs like: Presence, Flow, Cybersickness

### 3.1 Presence
Presence: "the feeling of being there"

#### Dimensions of Presence:
- Physical Presence: "the sense of being physically relocated to the virtual space"
- Social Presence: "the sense of being around other virtual beings"
Presence can vary from person to person: having high degrees of openness and extroversion tends to lead to higher presence
- Perceptions of the degree of environmental interaction
- Perceived fidelity and realism of the simulated environment

#### Measuring Presence
- Subjective Data (used more):
	- Self reporting questionnaires
		- Igroup Presence Questionnaire (IPQ)
			- Segregates Presence into 3 parts:
				- Spatial Presence: "the feeling of physical existence in the virtual space"
				- Involvement: "how captivated one is in the virtual world"
				- Experienced Realism/Realness: "how real the virtual world feels compared to the real world"
	- Interviews
- Objective Data
- Mix of both

### 3.2 Flow
Flow: "the mental state of extreme positive engagement, such that a person loses their self-consciousness"

#### Dimensions of Flow:
1. Clear goals, with immediate feedback
	- Feedback as to how progress to those goals are going (e.g. cycling, every push of the pedals drives a person a fixed distance closer)
2. Challenges that match a person's skill level
3. Complete concentration
4. Loss of self consciousness
5. Sense of control
6. Effortlessness
7. Transformation of time
8. Autotelic experience (intrinsic motivation, doing something because the person wants to)

#### Measuring Flow
- Subjective Data
	- Questionnaires
		- Flow State Scale & Flow State Scale 2,
			- Flow Short Scale (for shorter experiences)
				- Consolidates 8 flow dimensions into 3
					- Overall Flow
					- Absorption by Activity
					- Fluency of Performance

### 3.3 Cybersickness
Cybersickness: "symptoms of sickness due to cyber activities"
Cybersickness symptoms: Nausea, Dizziness, Disorientation, more physical discomforts...
Reducing Cybersickness: try to match the interactions of the real world as much as possible to a person's view of the virtual environment in a device

#### Measuring Cybersickness
- Subjective Data
	- Questionnaires: Simulator Sickness Questionnaire (SSQ), Virtual Reality Sickness Questionnaire (VRSQ), Cybersickness Questionnaire (CSQ)
		- Grouped into categories
			- Oculomotor(Eyes) Symptoms
			- Disorientation Symptoms
	- Qualitative Think-Aloud Data
- Objective Data
	- Skin conductance sensors (measure sweat)
	- Heart rate sensors
	- Electromyography (EMG), for face muscles

## 4. Affordances
Affordances: "the relationship between the properties of an object and the capabilities of an agent that determines how the system is used"
E.g. humans have hands that can curl around stuff, door knobs have small rounds surfaces that are about the size of a human hand -> a human may tend to curl their hand around a door knob

With regards to XR, some objects have very well defined affordances in the real world (people generally know how to hold a cup), but in XR, it depends on for the system/object is implemented (perhaps the programmers did not allow for cups to be picked up)

# End
Link: [Developing Immersive Applications: Evaluating Immersive Experiences - YouTube](https://www.youtube.com/watch?v=zNpo3Ue2Ui0)
> Written with [StackEdit](https://stackedit.io/).


# Development Primer
[Discussion Link](https://github.com/orgs/sit-dia/discussions/6)
## 1. Start
## 2. NodeJS and Node Package Manager
## 3. Node Version Manager
## 4. package.json
## 5. BabylonJS
## 6. TypeScript vs. JavaScript
## 7. Installing Webpack dependencies
## 8. Configuring Webpack & TypeScript
## 9. Starter code in index.html
## 10. Debugging in browsers
## 11. Hello World in TS
## 12. Creating a scene
## 13. Creating text using BabylonJS GUI library
## 14. Adding XR to the scene
## 15. Debugging with the Mozilla XR emulator
## 16. Async Programming
## 17. Debugging AR with the Mozilla XR emulator
## 18. Debugging on a physical Meta Quest 2
## 19. Debugging on an Android phone
## 20. Debugging on iOS

# End

Link: [Developing Immersive Applications: Development Primer](https://www.youtube.com/watch?v=iDCnmggNIy8)

> Written with [StackEdit](https://stackedit.io/).

# Development Tools
[Discussion Link](https://github.com/orgs/sit-dia/discussions/7)
## The Tools
### 1. Unity
- Is a public company
- Uses a component-based architecture
- Easy to create high-quality simulations or games
- Can be deployed to nearly any platform
- Has project templates for AR and VR

### 2. Unreal Engine
- Massive, feature-heavy
- Private company
- Component-based
- Has visual scripting, but also supports C++
- Good for making high-quality content with large teams
- The goto software when high-quality graphics are desired

### 3. A-Frame
- Is a JavaScript library
- Designed to be highly accessible to new developers
- Extensible to allow experienced developers to create highly complex VR experiences
- Web-based, so only builds for the web
- Held back by the immersion that is limited by the system (web browsers)
- Anyone with a browser will be able to experience XR creations (accessibility to users & developers)
- Open source
- The library creates custom HTML tags to be used in code
 
### 4. BabylonJS
- Is a JavaScript library
- Has supporting tools like Playground to allow for quick testing
- Has in-built rendering and physics libraries, focuses on performance more than A-Frame
- Large and active community
- Open source, fully supports WebXR
- Typescript is the default, not JavaScript

### 5. WebXR
- Is a set of open APIs that standardizes how XR apps are made for the web
- has support for different devices, gamepads, AR and more

### 6. OpenXR
- Is a C++ library, made by Khronos (the OpenGL & Vulkan people)
- Basically what WebXR is doing, but for native platforms instead of the web
- Is more specific with regard to deployment platforms
- Usually only needed if unique, novel features are necessary

### 7. Choice Factors when Selecting Tools
- E.g clients have Meta Quest Pro systems, used in medical training environments -> Unreal Engine
- E.g. Crowdsource camera footage through an AR game -> have as many users as possible -> BabylonJS

#### Non Functional Considerations of Tools
- Cost 
- Stability
- Customizability/extensibility
- Community + Support
- Learning Opportunities (does the tool align with learning objectives as a developer?)

## Why WebXR + BabylonJS
- End products will be more accessible to users, accessibility leads to adoption, leads to more feedback, leads to a better product
- Large, active developer community
- Accessibility to developers, will give prototypes longevity
- Nuanced technicalities, can help in designing more unique experiences
- Applied learning experience
 
# End

Link: [Developing Immersive Applications: Development Tools (youtube.com)](https://www.youtube.com/watch?v=qxNUQVsZ9Rk)

> Written with [StackEdit](https://stackedit.io/).


# Hardware and Software Components
[Discussion Link](https://github.com/orgs/sit-dia/discussions/9)
## 1. Variety of XR Devices
- XR = eXtended Reality, the intersection of the 3 sets AR, VR & MR
- Common dedicated XR Devices: Meta Quest series, HTC Vive, Microsoft Hololens

## 2. The HMD
- HMD = Head Mounted Device
- Were originally only meant for VR
- Can be used with PCs (PCVR) or standalone (All In One VR -> AIO)
- AR HMDs: Smartphones, Smartglasses

## 3. Hardware Components
- Meta Quest 2
	- Display Screen
	- 2x Magnifier Glasses
	- Optional Corrective lenses (so that wearing typical glasses is not necessary)
	- Specialised controllers, with infrared lights and motion tracking
	- Motion tracking in the main headset
	- Cameras all over the headset
	- Misc: Battery, speakers, CPU, GPU, motherboard (very similar to smartphone components)

## 4. Image Formation Process
### Side View
![Side view](https://github.com/MrLuigiBean/VRNotes/assets/84760999/ad415420-2842-4822-8a00-58f025338c2b)

- `h_disp` = height of the display (basically the width of a smartphone screen, since it is in a landscape orientation, not portrait)
- `d_disp` = distance between display and lens
- `f` = focal length of lens
- `d_eye` = eye relief (distance between eyes to the lens)
- From the Gaussian Thin Lens formula, 
	- `d_virt` = distance from lens to virtual image, calculated by `d_disp`, `f`
	- `h_virt` = height of virtual image, calculated by `h_disp`, `d_disp`, `f`
	- View frustum (near is the display, far is the virtual image) is _vertically symmetric_

### Top View
![Top View](https://github.com/MrLuigiBean/VRNotes/assets/84760999/d1e26f04-33c1-408e-a97f-14224bb2a770)

- `w_disp` = width of the display (basically the height of a smartphone screen, since it is in a landscape orientation, not portrait)
- `w_ipd` = interpupillary distance (distance between eyes/lenses)
- `w_virt1` = left width of virtual image, calculated by `w_disp`, `d_virt`, `w_ipd`
- `w_virt2` = right width of virtual image, calculated by `w_disp`, `d_virt`, `w_ipd`
- For the left eye, `w_virt1` > `w_virt2`. Vice-versa for the right eye.
- View frustum (near is the display, far is the virtual image) is _horizontally **asymmetric**_ -> different images for the left and right eyes

### Field Of View (FOV)
Side FOV
![Side FOV](https://github.com/MrLuigiBean/VRNotes/assets/84760999/53f28ce5-aeb0-4829-9646-6c998584a57e)

Top FOV
![Top FOV](https://github.com/MrLuigiBean/VRNotes/assets/84760999/2fe92014-3f92-4ffc-95fd-23c7d79d4fa6)


- `d` = distance from eye to virtual image
- `h` = height of virtual image
- `fov_h` = horizontal FOV angle, calculated by `fov_h_nasal` and `fov_h_temporal`, which use`w_ipd`, `d`
- `fov_h_nasal` = the FOV angle of the nose side
- `fov_h_temporal` = the FOV angle of the side of the temples
- `fov_v` = vertical FOV angle, calculated by `h`, `d`, `M`
- `M` = magnification factor (refer to slides for more context)

#### Types of FOV
- Binocular FOV: the combined visual span of **overlapping** region of both eyes
- Monocular FOV: the combined visual span of **non-overlapping** region of both eyes (the parts separately seen by each eye, peripheral vision)

## 5. Software Components
- Rendering
	- Helps produce the stereo images necessary
	- Need to manage 3D models and their textures
	- Lighting
	- Camera (User Viewpoint)
	- Post Processing (Bloom, Depth of Field)
- Physics
	- Takes care of how objects are simulated akin to real-life
	- Displacement
	- Velocity
	- Acceleration
	- Gravity
	- Need to specify response behaviours
- Input Handler
	- Manages input based on what hardware is available
	- Captures input events
	- Update positions based on the HMD's position & rotation
- Audio
	- Manages audio files
	- Load files
	- Decode files
	- Volume
	- Pitch
- AI
	- Facilitates the development of automated behaviours in animated objects
	- Level of intelligence to exhibit varies with the use case
	- Pathfinding/Navigation
	- Decision Making Tools (Finite State Machines)
	- Learning Mechanisms
- Networking, etc...

# End

Link: [Developing Immersive Applications: Hardware and Software Components](https://www.youtube.com/watch?v=OKD4jrnn4WE)

> Written with [StackEdit](https://stackedit.io/).

# Creating Virtual Environments
[Discussion Link](https://github.com/orgs/sit-dia/discussions/13)

## 1. Creating a Skybox
## 2. Creating Camera controls
## 3. Adding lighting
## 4. Creating VideoDome
## 5. Shortcuts for Inspector mode
## 6. Making VE respond to window size
## 7. Loading 3D Models
## 8. Async programming for loading models
## 9. Creating Animation
## 10. Creating Particle Systems
## 11. Adding Sound
## 12. Creating simple GUI controls
## 13. Adding GUI Interactions
## 14. GUI: VR vs. Desktop

## 15. Correction to Menti Questions
These are corrections to the [Week 06 - Menti pdf](Week%2006%20-%20Menti.pdf)
![image](https://github.com/TobyIO0085/VRNotes/assets/76524945/3797c9fd-b53b-425d-8a86-403211047306)
![image](https://github.com/TobyIO0085/VRNotes/assets/76524945/fc0fa0ed-b0fa-4cbe-9eec-36e512257bac)
![image](https://github.com/TobyIO0085/VRNotes/assets/76524945/63a32811-3559-4895-971f-4f0353ba3ae0)

# End

Link: [Developing Immersive Applications: Creating Virtual Environments (Recorded Live Stream)](https://www.youtube.com/watch?v=9crXku_K-0Y)

> Written with [StackEdit](https://stackedit.io/).
